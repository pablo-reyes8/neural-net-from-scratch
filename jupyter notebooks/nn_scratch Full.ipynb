{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Overview\n",
    "\n",
    "This self-contained Jupyter notebook implements every step of a neural network from scratch—without importing any code from `src/`. All functions (initialization, forward pass, backward pass, optimization, metrics, and plotting) are defined inline, making this notebook longer and more detailed for users who enjoy exploring every component in one place.\n",
    "\n",
    "**Notebook structure:**\n",
    "1. **Neural-Network Components (All Inline)**  \n",
    "   - Weight/bias initialization routines  \n",
    "   - Activation functions (ReLU, Sigmoid and more)  \n",
    "   - Loss function with L2 regularization  \n",
    "   - Forward and backward propagation loops  \n",
    "   - Adam optimizer implementation and normal gradient descend \n",
    "2. **Data Loading & Preprocessing**  \n",
    "   - Load the Customer Churn dataset  \n",
    "   - Split into train/validation/test sets  \n",
    "   - Scale features using standard normalization \n",
    "3. **Hyperparameter showcase**  \n",
    "   - Learning rates, hidden-layer sizes, batch sizes, regularization strengths \n",
    "4. **Training & Monitoring**  \n",
    "   - Detailed training loop with per-epoch console logging  \n",
    "   - Matplotlib plots of loss and accuracy curves inline  \n",
    "\n",
    "5. **Evaluation & Visualization**  \n",
    "   - Compute and display test accuracy, confusion matrix, and ROC curve  \n",
    "   - Inline code to plot ROC and precision-recall curves  \n",
    "\n",
    "By running this notebook from top to bottom, you will reproduce the full diabetes-prediction pipeline—with maximum transparency into every mathematical and coding detail. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets star making the blocks for the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    \"\"\"Rectified Linear Unit (ReLU) activation function.\n",
    "\n",
    "    Applies the ReLU operation during forward propagation and computes\n",
    "    its derivative during backpropagation.\n",
    "\n",
    "    Usage:\n",
    "        relu = ReLu()\n",
    "        a = relu(z)             # forward: max(0, z)\n",
    "        da_dz = relu(z, False)  # backward: derivative w.r.t. z\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, z, forw_prop=True):\n",
    "        \"\"\"Compute ReLU activation or its derivative.\n",
    "\n",
    "        Args:\n",
    "            z (array-like): Input array of pre-activation values.\n",
    "            forw_prop (bool, optional): If True (default), returns the\n",
    "                forward pass ReLU outputs; if False, returns the derivative\n",
    "                dReLU/dz for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Element-wise ReLU activations (if `forw_prop=True`)\n",
    "                or element-wise gradients (if `forw_prop=False`).\n",
    "        \"\"\"\n",
    "\n",
    "        z = np.asarray(z, dtype=np.float64)\n",
    "        \n",
    "        if forw_prop:\n",
    "            return np.maximum(0, z)\n",
    "        dz = np.zeros_like(z)\n",
    "        dz[z > 0] = 1\n",
    "        return dz\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"Sigmoid activation function.\n",
    "\n",
    "    Computes the logistic sigmoid during forward propagation and its\n",
    "    derivative during backpropagation.\n",
    "\n",
    "    Usage:\n",
    "        sig = Sigmoid()\n",
    "        a = sig(z)             # forward: 1 / (1 + exp(-z))\n",
    "        da_dz = sig(z, False)  # backward: sigmoid(z) * (1 − sigmoid(z))\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, z, forw_prop=True):\n",
    "        \"\"\"Compute sigmoid activation or its gradient.\n",
    "\n",
    "        Args:\n",
    "            z (array-like): Input pre-activation values.\n",
    "            forw_prop (bool, optional): If True (default), returns the\n",
    "                sigmoid outputs; if False, returns the derivative\n",
    "                dσ/dz for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Element-wise sigmoid activations (if `forw_prop=True`)\n",
    "                or gradients (if `forw_prop=False`).\n",
    "        \"\"\"\n",
    "\n",
    "        z = np.asarray(z, dtype=np.float64)\n",
    "        z = np.clip(z, -500, 500)\n",
    "\n",
    "        sigm = 1 / (1 + np.exp(-z))\n",
    "        if forw_prop:\n",
    "            return sigm\n",
    "        return sigm * (1 - sigm)\n",
    "    \n",
    "class LeakyReLu:\n",
    "    \"\"\"Leaky Rectified Linear Unit (Leaky ReLU) activation function,\n",
    "    sin __init__, con pendiente α fija.\n",
    "\n",
    "    Forward:  f(z) = z     if z > 0\n",
    "                    α·z    otherwise\n",
    "\n",
    "    Backward: f'(z) = 1     if z > 0\n",
    "                    α       otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    # pendiente en la parte negativa\n",
    "    alpha = 0.01\n",
    "\n",
    "    def __call__(self, z, forw_prop: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z (array-like): pre-activations.\n",
    "            forw_prop (bool): True → forward; False → derivada.\n",
    "        \"\"\"\n",
    "        z = np.asarray(z, dtype=np.float64)\n",
    "\n",
    "        if forw_prop:\n",
    "            return np.where(z > 0, z, self.alpha * z)\n",
    "        \n",
    "        # Derivate\n",
    "        dz = np.ones_like(z)\n",
    "        dz[z < 0] = self.alpha\n",
    "        return dz\n",
    "    \n",
    "\n",
    "class Tanh:\n",
    "    \"\"\"Hyperbolic tangent (tanh) activation function.\n",
    "\n",
    "    Computes the tanh activation during forward propagation and its\n",
    "    derivative during backpropagation.\n",
    "\n",
    "    Usage:\n",
    "        tanh = Tanh()\n",
    "        a = tanh(z)             # forward: tanh(z)\n",
    "        da_dz = tanh(z, False)  # backward: 1 − tanh(z)**2\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, z, forw_prop=True):\n",
    "        \"\"\"Compute tanh activation or its gradient.\n",
    "\n",
    "        Args:\n",
    "            z (array-like): Input pre-activation values.\n",
    "            forw_prop (bool, optional): If True (default), returns the\n",
    "                tanh outputs; if False, returns the derivative\n",
    "                d(tanh)/dz for backpropagation.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Element-wise tanh activations (if `forw_prop=True`)\n",
    "                or gradients (if `forw_prop=False`).\n",
    "        \"\"\"\n",
    "\n",
    "        z = np.asarray(z, dtype=np.float64)\n",
    "        z = np.clip(z, -500, 500)\n",
    "\n",
    "        tan = np.tanh(z)\n",
    "        if forw_prop:\n",
    "            return tan\n",
    "        return 1 - tan**2\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"Softmax activation function.\n",
    "\n",
    "    Computes the softmax probabilities during forward propagation and the\n",
    "    corresponding Jacobian matrices during backpropagation.\n",
    "\n",
    "    Usage:\n",
    "        softmax = Softmax()\n",
    "        A = softmax(z)             # forward: softmax across each column\n",
    "        J = softmax(z, False)      # backward: Jacobian(s) dA/dz\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, z, forw_prop=True):\n",
    "        \"\"\"Compute softmax activation or its Jacobian.\n",
    "\n",
    "        Args:\n",
    "            z (np.ndarray): Input array of shape (n, m), where each column\n",
    "                is a set of pre-activation values for n classes and m examples.\n",
    "            forw_prop (bool, optional): If True (default), returns the softmax\n",
    "                outputs; if False, returns the Jacobian matrix for each example.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray:\n",
    "                - If `forw_prop=True`: array of shape (n, m) with softmax\n",
    "                  probabilities for each column.\n",
    "                - If `forw_prop=False`:\n",
    "                    - shape (n, n) if `z` is 1D (n,) (single example),\n",
    "                    - shape (m, n, n) if `z` is 2D (n, m) (one Jacobian per column).\n",
    "        \"\"\"\n",
    "\n",
    "        shift = z - np.max(z, axis=0, keepdims=True)\n",
    "        exp_z = np.exp(shift)\n",
    "        A = exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "        if forw_prop:\n",
    "            return A\n",
    "        if z.ndim == 1:\n",
    "            return np.diag(A) - np.outer(A, A)\n",
    "        \n",
    "        n, m = A.shape\n",
    "\n",
    "        jacobianas = np.zeros((m, n, n))\n",
    "        for i in range(m):\n",
    "            ai = A[:, i]\n",
    "            jacobianas[i] = np.diag(ai) - np.outer(ai, ai)\n",
    "        return jacobianas\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size=64, seed=None):\n",
    "    \"\"\"Generate a list of random mini-batches from (X, Y).\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Input data of shape (n_x, m), where m is the number of examples.\n",
    "        Y (np.ndarray): Labels of shape (n_y, m) or (m,); will be reshaped to (1, m) if needed.\n",
    "        mini_batch_size (int, optional): Size of each mini-batch. Defaults to 64.\n",
    "        seed (int, optional): Random seed for reproducibility. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: A list where each element is a tuple\n",
    "            `(mini_batch_X, mini_batch_Y)` with shapes\n",
    "            `(n_x, mini_batch_size)` and `(n_y, mini_batch_size)` (except the last batch\n",
    "            which may be smaller if m is not divisible by `mini_batch_size`).\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[1]\n",
    "    if Y.ndim == 1:\n",
    "        Y = Y.reshape(1, m)\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    permutation = rng.permutation(m)\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation]\n",
    "\n",
    "    mini_batches = []\n",
    "    num_complete = math.floor(m / mini_batch_size)\n",
    "    for k in range(num_complete):\n",
    "        start = k * mini_batch_size\n",
    "        end   = start + mini_batch_size\n",
    "\n",
    "        mini_batches.append((shuffled_X[:, start:end],shuffled_Y[:, start:end]))\n",
    "\n",
    "    if m % mini_batch_size != 0:\n",
    "        start = num_complete * mini_batch_size\n",
    "        mini_batches.append((shuffled_X[:, start: ],shuffled_Y[:, start: ]))\n",
    "\n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def iniciar_parametros(shape_nn:list , inicialization='Rand' , he_init = None , escala = 0.01):\n",
    "    \"\"\"Initialize neural network parameters.\n",
    "\n",
    "    Supports standard random scaling or selective He initialization.\n",
    "\n",
    "    Args:\n",
    "        shape_nn (list of int): Layer sizes including input, e.g. [n_x, n_h1, ..., n_y].\n",
    "        initialization (str, optional): \n",
    "            - 'Rand': random normal * scale  \n",
    "            - 'He_Normal': He initialization on layers flagged in `he_init`.  \n",
    "            Defaults to 'Rand'.\n",
    "        he_init (list of bool, optional): Flags (one per layer transition) indicating\n",
    "            which layers use He initialization when `initialization='He_Normal'`.\n",
    "            Length must be `len(shape_nn) - 1`. Defaults to None.\n",
    "        scale (float, optional): Scaling factor for the 'Rand' method. Defaults to 0.01.\n",
    "\n",
    "    Returns:\n",
    "        dict or str:\n",
    "            If successful, returns a dict with keys:\n",
    "                W{i} (ndarray): weights of layer i, shape (shape_nn[i], shape_nn[i-1])\n",
    "                b{i} (ndarray): biases of layer i, shape (shape_nn[i], 1)\n",
    "            If invalid options are provided, returns an error message string.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: \n",
    "            - If `initialization` is not 'Rand' or 'He_Normal'.\n",
    "            - If `he_init` length mismatches `len(shape_nn) - 1` when using 'He_Normal'.\n",
    "    \"\"\"\n",
    "\n",
    "    parameters = {}\n",
    "\n",
    "    dim_layer = len(shape_nn)\n",
    "\n",
    "\n",
    "    if inicialization == 'He_Normal' and he_init == None:\n",
    "        bools = [False] + [1 for _ in range(len(shape_nn)-1)]\n",
    "        he_init = bools[1:]\n",
    "    elif inicialization == 'He_Normal' and isinstance(he_init , list):\n",
    "        bools = [False] + [bool(x) for x in he_init]\n",
    "    elif inicialization == 'He_Normal' and not(isinstance(he_init , list)):\n",
    "        raise ValueError('He_init debe ser una lista')\n",
    "\n",
    "    if inicialization == 'Rand':\n",
    "        for i in range(1, dim_layer):\n",
    "            parameters['W' + str(i)] = np.random.randn(shape_nn[i],shape_nn[i-1]) * escala\n",
    "            parameters['b' + str(i)] = np.zeros((shape_nn[i], 1))\n",
    "\n",
    "    elif inicialization == 'He_Normal':\n",
    "        if len(he_init) != (len(shape_nn)-1):\n",
    "            raise ValueError('`he_init` debe tener longitud igual a `len(shape_nn) - 1`')\n",
    "        \n",
    "        for i in range(1, dim_layer):\n",
    "            if bools[i]:\n",
    "                parameters['W' + str(i)] = np.random.randn(shape_nn[i],shape_nn[i-1]) * np.sqrt(2/shape_nn[i-1])\n",
    "                parameters['b' + str(i)] = np.zeros((shape_nn[i], 1))\n",
    "            else:\n",
    "                parameters['W' + str(i)] = np.random.randn(shape_nn[i],shape_nn[i-1]) * escala\n",
    "                parameters['b' + str(i)] = np.zeros((shape_nn[i], 1))\n",
    "    else:\n",
    "        raise ValueError(\"`inicialization` debe ser 'Rand' o 'He_Normal'\")\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def one_layer_forward(A_prev , w , b , activation):\n",
    "    \"\"\"Perform forward propagation for a single neural network layer.\n",
    "\n",
    "    Args:\n",
    "        A_prev (np.ndarray): Activations from the previous layer,\n",
    "            shape (size_prev, m), where m is the batch size.\n",
    "        w (np.ndarray): Weights matrix for the current layer,\n",
    "            shape (size_current, size_prev).\n",
    "        b (np.ndarray): Bias vector for the current layer,\n",
    "            shape (size_current, 1).\n",
    "        activation (str): Name of the activation function to apply.\n",
    "            Supported values: 'relu', 'sigmoid', 'tanh', 'softmax'.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            A (np.ndarray): Activations for the current layer,\n",
    "                shape (size_current, m).\n",
    "            forward_vars (tuple): Cached values (Z, w, b) for use in backpropagation.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If `activation` is not one of the supported keys.\n",
    "    \"\"\"\n",
    "\n",
    "    activaciones = {\n",
    "    'relu': ReLu(),\n",
    "    'sigmoid': Sigmoid(),\n",
    "    'tanh': Tanh(),\n",
    "    'leaky_relu': LeakyReLu(),\n",
    "    'softmax': Softmax()}\n",
    "\n",
    "    Z = w @ A_prev + b\n",
    "    if activation == 'relu':\n",
    "        A = activaciones['relu'](Z)\n",
    "\n",
    "    elif activation == 'tanh':\n",
    "        A = activaciones['tanh'](Z)\n",
    "\n",
    "    elif activation == 'sigmoid':\n",
    "        A = activaciones['sigmoid'](Z)\n",
    "\n",
    "    elif activation == 'softmax':\n",
    "        A = activaciones['softmax'](Z)\n",
    "\n",
    "    forward_vars = (Z , w , b)\n",
    "\n",
    "    return A , forward_vars\n",
    "\n",
    "\n",
    "def forward_pass(X , parameters , activations):\n",
    "    \"\"\"Perform a full forward pass through a multi-layer neural network.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Input data of shape (n_x, m), where m is the number of examples.\n",
    "        parameters (dict): Dictionary containing network parameters:\n",
    "            - 'W{i}' (np.ndarray): weight matrix for layer i.\n",
    "            - 'b{i}' (np.ndarray): bias vector for layer i.\n",
    "          There should be 2·L entries for an L-layer network.\n",
    "        activations (list of str): List of activation names to apply at each layer,\n",
    "            length L. Supported: 'relu', 'sigmoid', 'tanh', 'softmax'.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            A_final (np.ndarray): Activations from the last layer, shape (n_y, m).\n",
    "            caches (dict): Cached values for backpropagation. Contains for each layer i:\n",
    "                - 'A{i-1}': activations from previous layer,\n",
    "                - 'Z{i}': pre-activation,\n",
    "                - 'W{i}', 'b{i}': parameters for layer i,\n",
    "                - 'A{i}': activations of layer i.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the number of activations does not match the number of layers.\n",
    "    \"\"\"\n",
    "\n",
    "    A = X \n",
    "    layers = len(parameters) // 2 \n",
    "    if len(activations) != layers: \n",
    "        return f'El numero de funciones de activacion no coincide'\n",
    "    \n",
    "    caches = {}\n",
    "    caches['A' + str(0)] = X\n",
    "\n",
    "    for i in range(1, layers):\n",
    "        A_prev = A\n",
    "        A ,  forward_vars =  one_layer_forward(A_prev , parameters['W' + str(i)] , parameters['b' + str(i)] , activations[i-1])\n",
    "        caches['W' + str(i)] = forward_vars[1]\n",
    "        caches['b' + str(i)] = forward_vars[2]\n",
    "        caches['Z' + str(i)] = forward_vars[0]\n",
    "        caches['A' + str(i)] = A\n",
    "    \n",
    "\n",
    "    A_final , forward_vars_final =  one_layer_forward(A , parameters['W' + str(layers)] , parameters['b' + str(layers)] , activations[layers-1])\n",
    "    caches['W' + str(layers)] = forward_vars_final[1]\n",
    "    caches['b' + str(layers)] = forward_vars_final[2]\n",
    "    caches['Z' + str(layers)] = forward_vars_final[0]\n",
    "\n",
    "    return A_final , caches \n",
    "\n",
    "\n",
    "def compute_cost(A_final , labels , tipe , caches ,regularization = False , lambda_reg = None ):\n",
    "    \"\"\"Compute the loss between predicted probabilities and true labels, with optional L2 regularization.\n",
    "\n",
    "    Supports binary cross-entropy for two-class problems or categorical\n",
    "    cross-entropy for multi-class problems. When `regularization=True`, adds\n",
    "    an L2 penalty term λ/(2m)·∑‖W‖² over all weight matrices stored in `caches`.\n",
    "\n",
    "    Args:\n",
    "        A_final (np.ndarray): Predicted probabilities, shape (n_y, m).\n",
    "        labels (np.ndarray): True labels, shape (n_y, m) or (m,); will be\n",
    "            reshaped to (1, m) if necessary.\n",
    "        tipe (str): Type of cost to compute:\n",
    "            - 'BinaryCrossEntropy': binary cross-entropy loss.\n",
    "            - 'CrossEntropy': categorical cross-entropy loss.\n",
    "        caches (dict, optional): Dictionary of cached values from forward pass.\n",
    "            Used to extract weight matrices 'W1', 'W2', … when `regularization=True`.\n",
    "        regularization (bool, optional): If True, include L2 penalty. Defaults to False.\n",
    "        lambda_reg (float, optional): Regularization strength λ for L2 penalty.\n",
    "            Must be ≥ 0. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        float: The scalar loss value (including regularization term if enabled).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `tipe` is not one of the supported cost types.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure labels are shape (n_y, m)\n",
    "    if labels.ndim == 1:\n",
    "        labels = labels.reshape(1, -1)\n",
    "\n",
    "    m = labels.shape[1]\n",
    "    eps = 1e-15\n",
    "    A_safe = np.clip(A_final, eps, 1 - eps)\n",
    "\n",
    "    # Compute base cost\n",
    "    if tipe == 'BinaryCrossEntropy':\n",
    "        logprobs = (labels * np.log(A_safe) +\n",
    "                    (1 - labels) * np.log(1 - A_safe))\n",
    "        cost = - (1 / m) * np.sum(logprobs)\n",
    "\n",
    "    elif tipe == 'CrossEntropy':\n",
    "        logprobs = labels * np.log(A_safe)\n",
    "        cost = - (1 / m) * np.sum(logprobs)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"`tipe` must be 'BinaryCrossEntropy' or 'CrossEntropy'\")\n",
    "\n",
    "    # Add L2 regularization term if requested\n",
    "    if regularization:\n",
    "        if lambda_reg < 0:\n",
    "            raise ValueError(\"`lambda_reg` must be non-negative for L2 regularization\")\n",
    "        \n",
    "        if caches is None:\n",
    "            raise ValueError(\"`caches` must be provided when using regularization\")\n",
    "        \n",
    "        l2_sum = sum(np.sum(W**2) for name, W in caches.items() if name.startswith('W'))\n",
    "        cost += (lambda_reg / (2 * m)) * l2_sum\n",
    "\n",
    "    return float(np.squeeze(cost))\n",
    "    \n",
    "\n",
    "\n",
    "def back_propagation(A_fianl , labels , activations , caches , regularization = False , lambda_reg = None):\n",
    "    \"\"\"Perform backpropagation through a multi-layer neural network, with optional L2 regularization.\n",
    "\n",
    "    Computes gradients of the loss with respect to parameters for each layer,\n",
    "    assuming the final activation is either sigmoid (binary classification)\n",
    "    or softmax (multi-class classification). When `regularization='L2'`, adds\n",
    "    the derivative of the L2 penalty (λ/m·W) to each dW.\n",
    "\n",
    "    Args:\n",
    "        A_final (np.ndarray): Output activations from the last layer, shape (n_y, m).\n",
    "        labels (np.ndarray): True labels, shape (n_y, m).\n",
    "        activations (list of str): Activation names for each layer, length L.\n",
    "            Supported: 'relu', 'sigmoid', 'tanh', 'softmax' (only for final layer).\n",
    "        caches (dict): Cached forward values from `forward_pass`, containing for\n",
    "            each layer i:\n",
    "            - 'Z{i}': pre-activation, shape (n_i, m)\n",
    "            - 'W{i}': weights, shape (n_i, n_{i-1})\n",
    "            - 'A{i}': activations, shape (n_i, m)\n",
    "        regularization (bool or str, optional): If 'L2', apply L2 regularization.\n",
    "            If False (default), no regularization.\n",
    "        lambda_reg (float, optional): Regularization strength λ for L2 penalty.\n",
    "            Must be ≥ 0. Default is 0.0.\n",
    "\n",
    "    Returns:\n",
    "        dict: Gradients with keys for each layer i:\n",
    "            - 'dZ{i}': gradient of loss w.r.t. Z{i}\n",
    "            - 'dW{i}': gradient of loss w.r.t. W{i} (including λ·W/m if L2)\n",
    "            - 'db{i}': gradient of loss w.r.t. b{i}\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the final activation is not 'sigmoid' or 'softmax',\n",
    "                    or if `lambda_reg` < 0 when using L2 regularization.\n",
    "    \"\"\"\n",
    "\n",
    "    activation_names = {'relu': ReLu() , 'sigmoid': Sigmoid() , 'tanh': Tanh() ,'leaky_relu': LeakyReLu()}\n",
    "    back_prop_caches = {}\n",
    "    layers = len(activations)\n",
    "    m = labels.shape[1]\n",
    "\n",
    "    if regularization == 'L2' and (lambda_reg is None or lambda_reg < 0):\n",
    "        raise ValueError(\"Para L2 regularization, lambda_reg debe ser ≥ 0\")\n",
    "    \n",
    "    #Compute Last Layer derivates:\n",
    "    if activations[-1] in ('sigmoid', 'softmax'):\n",
    "        dZ_fin = A_fianl - labels\n",
    "        dW_fin = 1/m * (dZ_fin @ caches['A' + str(layers-1)].T)\n",
    "\n",
    "        if regularization == 'L2' :\n",
    "            dW_fin = dW_fin + (lambda_reg/m) * caches['W' + str(layers)]\n",
    "\n",
    "        db_fin = 1/m * np.sum(dZ_fin , axis=1 , keepdims=True)\n",
    "\n",
    "        back_prop_caches['dZ' + str(layers)]  , back_prop_caches['dW' + str(layers)] , back_prop_caches['db' + str(layers)] = dZ_fin ,dW_fin ,db_fin\n",
    "\n",
    "    else:\n",
    "        return f'La funcion de activacion final no es valida'\n",
    "        \n",
    "    # Calcular gradientes de todas las capas ocultas: \n",
    "    for i in range(layers-1 ,0 , -1):\n",
    "        act_actual = activations[i-1]\n",
    "        dA_i = caches['W' + str(i+1)].T @ back_prop_caches['dZ' + str(i+1)]\n",
    "        dZ_i = dA_i * activation_names[act_actual](caches['Z' + str(i)] , forw_prop=False )\n",
    "        dW_i = 1/m * (dZ_i @ caches['A' + str(i-1)].T)\n",
    "\n",
    "        if regularization == 'L2':\n",
    "            dW_i = dW_i + (lambda_reg/m) * caches['W' + str(i)]\n",
    "\n",
    "        db_i = 1/m * np.sum(dZ_i , axis=1 , keepdims=True)\n",
    "\n",
    "        back_prop_caches['dZ' + str(i)]  , back_prop_caches['dW' + str(i)]  , back_prop_caches['db' + str(i)] = dZ_i , dW_i ,db_i\n",
    "    \n",
    "    return back_prop_caches \n",
    "\n",
    "def update_gd_parameters(parameters, back_caches, lr):\n",
    "    \"\"\"Update network parameters using vanilla gradient descent.\n",
    "\n",
    "    Args:\n",
    "        parameters (dict): Current parameters of the network, with keys:\n",
    "            - 'W{i}' (np.ndarray): weight matrix for layer i.\n",
    "            - 'b{i}' (np.ndarray): bias vector for layer i.\n",
    "        back_caches (dict): Gradients from backpropagation, with keys:\n",
    "            - 'dW{i}' (np.ndarray): gradient of loss w.r.t. W{i}.\n",
    "            - 'db{i}' (np.ndarray): gradient of loss w.r.t. b{i}.\n",
    "        lr (float): Learning rate.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated parameters after one gradient descent step. Each\n",
    "            W{i} and b{i} is adjusted by subtracting lr * gradient.\n",
    "    \"\"\"\n",
    "\n",
    "    parameters = copy.deepcopy(parameters)\n",
    "    layers = len(parameters) // 2 \n",
    "\n",
    "    for l in range(layers):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - lr * back_caches[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - lr * back_caches[\"db\" + str(l + 1)]\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def iniciar_params_adam(parameters):\n",
    "    \"\"\"Initialize Adam optimizer’s first and second moment variables.\n",
    "\n",
    "    Args:\n",
    "        parameters (dict): Network parameters with keys:\n",
    "            - 'W{i}' (np.ndarray): weight matrix for layer i.\n",
    "            - 'b{i}' (np.ndarray): bias vector for layer i.\n",
    "          There should be 2·L entries for an L-layer network.\n",
    "\n",
    "    Returns:\n",
    "        tuple of dict:\n",
    "            v (dict): Initialized first moment estimates with keys\n",
    "                'dW{i}' and 'db{i}', each an array of zeros matching\n",
    "                the shape of the corresponding parameter.\n",
    "            s (dict): Initialized second moment estimates with keys\n",
    "                'dW{i}' and 'db{i}', each an array of zeros matching\n",
    "                the shape of the corresponding parameter.\n",
    "\n",
    "    \"\"\"\n",
    "     \n",
    "    layers  = len(parameters) // 2 \n",
    "    v = {}\n",
    "    s = {}\n",
    "\n",
    "    for l in range(1, layers + 1):\n",
    "        v[\"dW\" + str(l)] = np.zeros_like(parameters[\"W\" + str(l)])\n",
    "        v[\"db\" + str(l)] = np.zeros_like(parameters[\"b\" + str(l)])\n",
    "        s[\"dW\" + str(l)] = np.zeros_like(parameters[\"W\" + str(l)])\n",
    "        s[\"db\" + str(l)] = np.zeros_like(parameters[\"b\" + str(l)])\n",
    "    return v, s\n",
    "\n",
    "\n",
    "\n",
    "def adam(back_caches , parameters , v , s , t , learning_rate = 0.01 , beta1 = 0.9, beta2 = 0.999 ,epsilon = 1e-8):\n",
    "    \"\"\"Update parameters using the Adam optimization algorithm.\n",
    "\n",
    "    Applies bias-corrected first and second moment estimates to perform\n",
    "    an adaptive gradient update on each parameter.\n",
    "\n",
    "    Args:\n",
    "        back_caches (dict): Gradients from backprop, with keys:\n",
    "            - 'dW{i}' and 'db{i}' for each layer i.\n",
    "        parameters (dict): Current network parameters, with keys:\n",
    "            - 'W{i}' and 'b{i}' for each layer i.\n",
    "        v (dict): Exponential moving averages of past gradients (first moment).\n",
    "        s (dict): Exponential moving averages of past squared gradients (second moment).\n",
    "        t (int): Time step (iteration count) for bias correction.\n",
    "        learning_rate (float, optional): Step size. Defaults to 0.01.\n",
    "        beta1 (float, optional): Decay rate for the first moment. Defaults to 0.9.\n",
    "        beta2 (float, optional): Decay rate for the second moment. Defaults to 0.999.\n",
    "        epsilon (float, optional): Small constant to prevent division by zero. Defaults to 1e-8.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated parameters dictionary with the same keys as `parameters`.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    parameters = copy.deepcopy(parameters)\n",
    "    v_corrected = {}\n",
    "    s_corrected = {}\n",
    "    layers = len(parameters) // 2\n",
    "    \n",
    "    for i in range(1, layers + 1):\n",
    "        v[\"dW\" + str(i)] = beta1*(v[\"dW\" + str(i)]) + (1-beta1) * back_caches[\"dW\" + str(i)]\n",
    "        v[\"db\" + str(i)] = beta1*(v[\"db\" + str(i)]) + (1-beta1) * back_caches[\"db\" + str(i)]\n",
    "\n",
    "        s[\"dW\" + str(i)] = beta2*(s[\"dW\" + str(i)]) + (1-beta2) * (back_caches[\"dW\" + str(i)]**(2))\n",
    "        s[\"db\" + str(i)] = beta2*(s[\"db\" + str(i)]) + (1-beta2) * (back_caches[\"db\" + str(i)]**(2))\n",
    "\n",
    "        v_corrected[\"dW\" + str(i)] = v[\"dW\" + str(i)] / (1 - beta1**t)\n",
    "        v_corrected[\"db\" + str(i)] = v[\"db\" + str(i)] / (1 - beta1**t)\n",
    "\n",
    "        s_corrected[\"dW\" + str(i)] = s[\"dW\" + str(i)] / (1 - beta2**t)\n",
    "        s_corrected[\"db\" + str(i)] = s[\"db\" + str(i)] / (1 - beta2**t)\n",
    "\n",
    "        \n",
    "        parameters[\"W\" + str(i)] = parameters[\"W\" + str(i)] - learning_rate*(v_corrected[\"dW\" + str(i)]/( np.sqrt( s_corrected[\"dW\"+str(i)] ) + epsilon ))\n",
    "        parameters[\"b\" + str(i)] = parameters[\"b\" + str(i)] - learning_rate*(v_corrected[\"db\" + str(i)]/( np.sqrt( s_corrected[\"db\"+str(i)] ) + epsilon ))\n",
    "    \n",
    "    return parameters \n",
    "\n",
    "\n",
    "def learning_decay(learning_rate0, epoch_num, decay_rate):\n",
    "    \"\"\"Compute an updated learning rate using inverse time decay.\n",
    "\n",
    "    The learning rate is scaled by 1 / (1 + decay_rate * epoch_num), so it\n",
    "    decreases over epochs.\n",
    "\n",
    "    Args:\n",
    "        learning_rate0 (float): Initial learning rate before decay.\n",
    "        epoch_num (int): Current epoch index (often starting at 0).\n",
    "        decay_rate (float): Decay coefficient controlling the rate of decrease.\n",
    "\n",
    "    Returns:\n",
    "        float: Decayed learning rate:\n",
    "            learning_rate0 / (1 + decay_rate * epoch_num)\n",
    "    \"\"\"\n",
    "\n",
    "    learning_rate = 1 / ((1 + decay_rate * epoch_num)) * learning_rate0\n",
    "    return learning_rate\n",
    "\n",
    "\n",
    "def predict(X , y , parameters, activations , train = False , reg = False , lambda_reg=None , way=None):\n",
    "    \"\"\"Make predictions with a trained binary classification network and evaluate performance.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Input features of shape (n_x, m), where m is the number of examples.\n",
    "        y (np.ndarray): True binary labels of shape (1, m) or (m,); will be compared element-wise.\n",
    "        parameters (dict): Learned network parameters (weights and biases).\n",
    "        activations (list of str): Activation names for each layer, length L.\n",
    "        train (bool, optional): If False (default), prints cost and accuracy on the given data\n",
    "            and returns predictions; if True, returns only accuracy (for training).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray or float:\n",
    "            - If `train=False`: Returns `preds`, a (1, m) array of binary predictions {0,1}.\n",
    "            - If `train=True`: Returns `accuracy`, the fraction of correct predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    cost_total = 0\n",
    "    A_pred, _ = forward_pass(X, parameters, activations ) \n",
    "\n",
    "    if reg == False:\n",
    "        cost_total = cost_total + compute_cost(A_pred , y , 'BinaryCrossEntropy', parameters)\n",
    "    elif reg == 'L2':\n",
    "        cost_total = cost_total + compute_cost(A_pred , y , 'BinaryCrossEntropy', parameters , reg , lambda_reg)\n",
    "        \n",
    "    preds = (A_pred > 0.5).astype(int) \n",
    "    accuracy = np.mean(preds == y) \n",
    "\n",
    "    if train == False and way== 'val':\n",
    "        print(f\"En validacion el modelo logro: cost = {cost_total:.6f} — accuracy = {accuracy*100:.2f}%\")\n",
    "        return preds\n",
    "    elif train == False and way== 'test':\n",
    "        print(f\"En testeo el modelo logro: cost = {cost_total:.6f} — accuracy = {accuracy*100:.2f}%\")\n",
    "        return preds\n",
    "    else:\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets import a df to train the neural network we just created and also implement a manual standarization for numerical and categorical features and manual split into train val test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 7000) (7000,)\n",
      "(17, 2000) (2000,)\n",
      "(17, 1000) (1000,)\n"
     ]
    }
   ],
   "source": [
    "data_frame = pd.read_csv('../Data/Customer-Churn-Records.csv')\n",
    "\n",
    "X = data_frame.drop(columns='Exited')\n",
    "y = data_frame['Exited']\n",
    "\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "## Transformar datos: \n",
    "\n",
    "def manual_standardize(df, column):\n",
    "    \"\"\"Standardize a DataFrame column to zero mean and unit variance in-place.\n",
    "\n",
    "    Computes the column’s mean and population standard deviation (ddof=0)\n",
    "    then replaces values with their z-scores.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the target column.\n",
    "        column (str): Name of the column to standardize.\n",
    "\n",
    "    Returns:\n",
    "        None: Modifies `df[column]` in place.\n",
    "    \"\"\"\n",
    "\n",
    "    mean = df[column].mean()\n",
    "    std  = df[column].std(ddof=0)  \n",
    "    df[column] = (df[column] - mean) / std\n",
    "    return \n",
    "\n",
    "def label_encoder(df, column, encoder=None):\n",
    "    \n",
    "    \"\"\"Encode categorical values in a DataFrame column as integer labels.\n",
    "\n",
    "    Fits (or uses) a scikit-learn LabelEncoder to transform the specified column\n",
    "    in-place, converting each unique category to an integer.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the column to encode.\n",
    "        column (str): Name of the column with categorical values.\n",
    "        encoder (LabelEncoder, optional): Pre-instantiated encoder to use.\n",
    "            If None (default), a new LabelEncoder is created and fitted.\n",
    "\n",
    "    Returns:\n",
    "        LabelEncoder: The fitted encoder instance, useful for inverse transforms\n",
    "        or applying the same mapping to other datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    if encoder is None:\n",
    "        encoder = LabelEncoder()\n",
    "    df[column] = encoder.fit_transform(df[column].astype(str))\n",
    "    return encoder\n",
    "\n",
    "encoders = {}\n",
    "for col in X.columns:\n",
    "    if col in numeric_cols:\n",
    "        manual_standardize(X, col)\n",
    "    elif col in categorical_cols:\n",
    "        encoders[col] = label_encoder(X, col)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Change to Arrays \n",
    "X_array =  X.to_numpy()\n",
    "Y_array =  y.to_numpy()\n",
    "\n",
    "# Trian test split \n",
    "def train_val_test_split(X, y, train_pct, val_pct, test_pct):\n",
    "    \"\"\"Split datasets into training, validation, and test sets by specified proportions.\n",
    "\n",
    "    Converts inputs to NumPy arrays, ensures correct shapes, and splits along the\n",
    "    first axis (samples). Supports 1D or row-vector `y`.\n",
    "\n",
    "    Args:\n",
    "        X (array-like): Features of shape (m, n) or (n, m), where m is number of samples.\n",
    "        y (array-like): Labels of shape (m,) or (1, m) or (m, 1).\n",
    "        train_pct (float): Relative proportion for the training set.\n",
    "        val_pct (float): Relative proportion for the validation set.\n",
    "        test_pct (float): Relative proportion for the test set.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            X_train (np.ndarray): Training features.\n",
    "            X_val (np.ndarray): Validation features.\n",
    "            X_test (np.ndarray): Test features.\n",
    "            y_train (np.ndarray): Training labels.\n",
    "            y_val (np.ndarray): Validation labels.\n",
    "            y_test (np.ndarray): Test labels.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `y` has more than 2 dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "\n",
    "    if X.ndim == 2 and X.shape[0] < X.shape[1]:\n",
    "        X = X.T\n",
    "\n",
    "    if y.ndim == 2:\n",
    "        if y.shape[0] == 1:\n",
    "            y = y.flatten()\n",
    "        elif y.shape[1] == 1:\n",
    "            y = y.reshape(-1)\n",
    "    elif y.ndim != 1:\n",
    "        raise ValueError(f\"y debe ser 1-D o (1, m); llegó con ndim={y.ndim}\")\n",
    "    \n",
    "    total = train_pct + val_pct + test_pct\n",
    "    train_prop = train_pct / total\n",
    "    val_prop = val_pct / total\n",
    "\n",
    "    n = X.shape[0]\n",
    "    idx = np.arange(n)\n",
    "\n",
    "    train_end = int(np.floor(train_prop * n))\n",
    "    val_end = train_end + int(np.floor(val_prop * n))\n",
    "\n",
    "    train_idx = idx[:train_end]\n",
    "    val_idx = idx[train_end:val_end]\n",
    "    test_idx= idx[val_end:]\n",
    "\n",
    "    X_train= X[train_idx]\n",
    "    X_val= X[val_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_train= y[train_idx]\n",
    "    y_val= y[val_idx]\n",
    "    y_test= y[test_idx]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# Lets transpose the data to shapes the neural network understand\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X_array, Y_array, 70, 20, 10)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = X_train.T, X_val.T, X_test.T, y_train.T, y_val.T, y_test.T\n",
    "\n",
    "print(X_train.shape , y_train.shape)\n",
    "print(X_val.shape , y_val.shape)\n",
    "print(X_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can build the function that implements all the created functions to run a nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters you can tune in `model_nn_scratch`\n",
    "\n",
    "| Parameter           | Type                | Description                                          | Example values                 |\n",
    "|---------------------|---------------------|------------------------------------------------------|--------------------------------|\n",
    "| `layers_dims`       | `list[int]`         | Number of neurons per layer (incl. input & output)  | `[n_x, 64, 32, 1]`             |\n",
    "| `activations`       | `list[str]`         | Activation function for each layer                   | `['relu','tanh' , 'leaky_relu,'sigmoid' ]`    |\n",
    "| `optimizer`         | `str`               | Optimization algorithm                               | `'gd'` or `'Adam'`             |\n",
    "| `init`              | `None` or `str`     | Weight initialization                                | `None` (random) or `'He'` for Xavier init      |\n",
    "| `He_inits`          | `list[bool]`        | Flags per layer for applying He init (when `init='He'`) | `[True, True, False]`       |\n",
    "| `learning_rate`     | `float`             | Initial learning rate                                | `0.001`, `0.01`, …              |\n",
    "| `mini_batch_size`   | `int`               | Number of examples per mini‐batch                    | `32`, `64`, `128`, …            |\n",
    "| `beta`              | `float`             | Momentum coefficient (reserved for SGD+momentum)     | `0.9`                           |\n",
    "| `beta1`             | `float`             | Adam’s first‐moment decay rate                       | `0.9`                           |\n",
    "| `beta2`             | `float`             | Adam’s second‐moment decay rate                      | `0.999`                         |\n",
    "| `epsilon`           | `float`             | Adam’s numeric stability constant                    | `1e-8`                          |\n",
    "| `num_epochs`        | `int`               | Total training epochs                                | `100`, `500`, `1500`, …         |\n",
    "| `print_cost`        | `bool`              | Whether to print cost/accuracy during training       | `True` / `False`                |\n",
    "| `decay`             | `None` or `float`   | Inverse‐time learning rate decay rate (`None` disables) | `None` or `0.01`             |\n",
    "| `decay_rate`        | `float`             | Coefficient for inverse‐time decay                   | `1`, `0.1`, `0.001`             |\n",
    "| `regularization`    | `None` or `str`     | Weight decay type                                     | `None` or `'L2'`                |\n",
    "| `lambda_l2`         | `float`             | L2 regularization strength (λ)                       | `0.1`, `0.01`, `0.001`, `0.9`    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/80: cost = 0.002710 — accuracy = 78.00%\n",
      "Epoch   10/80: cost = 0.000308 — accuracy = 80.17%\n",
      "Epoch   20/80: cost = 0.000242 — accuracy = 81.50%\n",
      "Epoch   30/80: cost = 0.000249 — accuracy = 80.50%\n",
      "Epoch   40/80: cost = 0.000316 — accuracy = 31.00%\n",
      "Epoch   50/80: cost = 0.000192 — accuracy = 79.83%\n",
      "Epoch   60/80: cost = 0.000159 — accuracy = 85.33%\n",
      "Epoch   70/80: cost = 0.000136 — accuracy = 90.67%\n",
      "Epoch   79/80: cost = 0.000170 — accuracy = 99.17%\n"
     ]
    }
   ],
   "source": [
    "def model_nn_scratch(X, Y, layers_dims , activations, optimizer ,num_epochs, init=None ,He_inits = None, learning_rate = 0.001, mini_batch_size = 128, beta = 0.9,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8 , print_cost = True, decay=None, decay_rate=1 , regularization = None , lambda_l2 = 0.001):\n",
    "    \n",
    "    \"\"\"Train a deep neural network from scratch with optional optimizers, learning-rate decay, and L2 regularization.\n",
    "\n",
    "    This function supports vanilla gradient descent or Adam, inverse-time learning-rate decay,\n",
    "    and optional L2 weight decay. It returns the learned parameters and the cost history.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Input data of shape (n_x, m), where m is the number of examples.\n",
    "        Y (np.ndarray): True labels of shape (1, m).\n",
    "        layers_dims (list[int]): Neuron counts per layer, including input and output sizes.\n",
    "        activations (list[str]): Activation for each layer (length L), supports:\n",
    "            'relu', 'sigmoid', 'tanh', 'softmax' (softmax only for final layer).\n",
    "        optimizer (str): Optimization method, either 'gd' (gradient descent) or 'Adam'.\n",
    "        init (str or None, optional): Weight initialization method:\n",
    "            - None: random normal scaled by 0.01,\n",
    "            - 'He': He normal initialization (requires `He_inits` flags).\n",
    "        He_inits (list[bool], optional): Flags for applying He init per hidden layer (length L).\n",
    "        learning_rate (float, optional): Initial learning rate. Defaults to 0.001.\n",
    "        mini_batch_size (int, optional): Size of each mini-batch. Defaults to 128.\n",
    "        beta (float, optional): Momentum parameter (currently unused). Defaults to 0.9.\n",
    "        beta1 (float, optional): Exponential decay rate for Adam first moment. Defaults to 0.9.\n",
    "        beta2 (float, optional): Exponential decay rate for Adam second moment. Defaults to 0.999.\n",
    "        epsilon (float, optional): Small constant for Adam to prevent division by zero. Defaults to 1e-8.\n",
    "        num_epochs (int, optional): Number of training epochs. Defaults to 5000.\n",
    "        print_cost (bool, optional): If True, prints cost and accuracy at intervals. Defaults to True.\n",
    "        decay (float or None, optional): If provided, applies inverse-time decay to the learning rate.\n",
    "        decay_rate (float, optional): Decay rate for inverse-time schedule. Defaults to 1.\n",
    "        regularization (str or None, optional): If 'L2', apply L2 regularization; otherwise no regularization.\n",
    "        lambda_l2 (float, optional): L2 regularization strength λ (must be ≥ 0). Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            parameters (dict): Learned weights 'W1'…'WL' and biases 'b1'…'bL'.\n",
    "            costs (list[float]): Cost history per epoch (averaged over all examples).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `init` or `optimizer` is unrecognized, or if `lambda_l2` is negative when using L2.\n",
    "\n",
    "    Example:\n",
    "        >>> params, cost_hist = model_nn_scratch(\n",
    "        ...     X_train, Y_train,\n",
    "        ...     layers_dims=[n_x, 64, 32, 1],\n",
    "        ...     activations=['relu', 'relu', 'sigmoid'],\n",
    "        ...     optimizer='Adam',\n",
    "        ...     init='He',\n",
    "        ...     He_inits=[True, True, False],\n",
    "        ...     learning_rate=0.001,\n",
    "        ...     num_epochs=1000,\n",
    "        ...     regularization='L2',\n",
    "        ...     lambda_l2=0.01\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = [] \n",
    "    t = 0\n",
    "    m = X.shape[1]\n",
    "    learning_rate0 = learning_rate\n",
    "\n",
    "    # Initialize parameters\n",
    "    if init == None:\n",
    "        parameters = iniciar_parametros(layers_dims)\n",
    "    elif init == 'He':\n",
    "        parameters = iniciar_parametros(layers_dims , inicialization='He_Normal' , he_init = He_inits)\n",
    "    else:\n",
    "        return f'Inicializacion de pesos no valida'\n",
    "\n",
    "    # Initialize optimizer state\n",
    "    if optimizer == 'Adam':\n",
    "        v, s = iniciar_params_adam(parameters)\n",
    "    elif optimizer == 'gd':\n",
    "        pass \n",
    "    else:\n",
    "        return f'Optimizacion no reconocidio'\n",
    "    \n",
    "    # Determine print interval\n",
    "    if num_epochs < 100:\n",
    "        print_interval = 10\n",
    "    else:\n",
    "        print_interval = max(1, num_epochs // 10)\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(num_epochs):\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size)\n",
    "        epoch_cost = 0\n",
    "\n",
    "        for minibatch_X, minibatch_Y in minibatches:\n",
    "\n",
    "            A_final , caches_forward = forward_pass(minibatch_X , parameters , activations)\n",
    "\n",
    "            if regularization == 'L2':\n",
    "                epoch_cost = epoch_cost + compute_cost(A_final , minibatch_Y , 'BinaryCrossEntropy', caches_forward , regularization , lambda_l2)\n",
    "                caches_backwards = back_propagation(A_final , minibatch_Y , activations , caches_forward , regularization , lambda_l2)\n",
    "            else:\n",
    "                epoch_cost = epoch_cost + compute_cost(A_final , minibatch_Y , 'BinaryCrossEntropy', caches_forward)\n",
    "                caches_backwards = back_propagation(A_final , minibatch_Y , activations , caches_forward)\n",
    "            \n",
    "        \n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_gd_parameters(parameters, caches_backwards, learning_rate)\n",
    "            elif optimizer == \"Adam\":\n",
    "                t = t + 1\n",
    "                parameters = adam(caches_backwards , parameters , v , s , t , learning_rate)\n",
    "\n",
    "        # Average cost per example\n",
    "        cost_avg = epoch_cost / m\n",
    "        costs.append(cost_avg)\n",
    "        \n",
    "        if decay:\n",
    "            learning_rate = learning_decay(learning_rate0, i, decay_rate)\n",
    "\n",
    "        if print_cost and (i % print_interval == 0 or i == num_epochs-1):\n",
    "\n",
    "            if regularization == 'L2':\n",
    "                accuracy  = predict(minibatch_X ,  minibatch_Y , parameters, activations , train = True , reg=regularization , lambda_reg=lambda_l2)\n",
    "            else:\n",
    "                accuracy  = predict(minibatch_X ,  minibatch_Y , parameters, activations , train = True)\n",
    "\n",
    "            print(f\"Epoch {i:4d}/{num_epochs}: cost = {cost_avg:.6f} — accuracy = {accuracy*100:.2f}%\")\n",
    "            if decay:\n",
    "                print(f\"   lr = {learning_rate:.6e}\")\n",
    "            costs.append(cost_avg)\n",
    "\n",
    "    return parameters , costs\n",
    "\n",
    "\n",
    "layers_dims = [X_train.shape[0] , 50  , 10 , 1]\n",
    "activations = ['relu' , 'relu' , 'sigmoid']\n",
    "inicios = [1,0,1]\n",
    "lr = 0.001\n",
    "batch = 3200\n",
    "epochs = 80\n",
    "\n",
    "model , cost1 = model_nn_scratch(X_train, y_train, layers_dims , activations, 'Adam' , init='He' , He_inits = inicios , learning_rate = lr, mini_batch_size = batch, beta = 0.9,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = epochs, print_cost = True, decay=False, decay_rate=1 , regularization='L2' , lambda_l2= 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(cost1)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('epochs (per 100)')\n",
    "plt.title(\"Learning rate = \" + str(lr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the val and test set to diagnostic overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En validacion el modelo logro: cost = 0.266875 — accuracy = 99.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = predict(X_val , y_val , model, activations , way = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En testeo el modelo logro: cost = 0.271343 — accuracy = 98.20%\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict(X_test , y_test , model, activations , way = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets see the ROC curve and clasification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Clase 0      0.982     0.996     0.989       820\n",
      "     Clase 1      0.982     0.917     0.948       180\n",
      "\n",
      "    accuracy                          0.982      1000\n",
      "   macro avg      0.982     0.957     0.969      1000\n",
      "weighted avg      0.982     0.982     0.982      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "report = classification_report(\n",
    "    y_test.T,\n",
    "    y_pred_test.T,\n",
    "    target_names=['Clase 0', 'Clase 1'],\n",
    "    digits=3)\n",
    "\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test.T, y_pred_test.T)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Baseline')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation set**  \n",
    "- Cost: 0.2669  \n",
    "- Accuracy: 99.0%  \n",
    "\n",
    "**Test set**  \n",
    "- Cost: 0.2713  \n",
    "- Accuracy: 98.2%  \n",
    "\n",
    "**Classification Report**  \n",
    "- **Class 0:** Precision 0.982, Recall 0.996, F1-score 0.989 (Support 820)  \n",
    "- **Class 1:** Precision 0.982, Recall 0.917, F1-score 0.948 (Support 180)  \n",
    "- **Overall accuracy:** 0.982  \n",
    "- **Macro average:** Precision 0.982, Recall 0.957, F1-score 0.969  \n",
    "- **Weighted average:** Precision 0.982, Recall 0.982, F1-score 0.982  \n",
    "\n",
    "Beyond the raw scores, these results tell us that the network is exceptionally reliable at identifying both churners and non-churners:\n",
    "\n",
    "- **Robust learning and generalization:**  \n",
    "  The nearly identical costs (0.2669 vs. 0.2713) and accuracies (99.0% vs. 98.2%) on validation and test sets indicate minimal overfitting. The model has captured true patterns in the data rather than noise.\n",
    "\n",
    "- **Excellent performance on the majority class (non-churners):**  \n",
    "  With recall of 0.996, almost every non-churner is correctly identified, minimizing false alarms. High precision (0.982) also shows few non-churners are misclassified as churners.\n",
    "\n",
    "- **Strong—but slightly lower—detection of churners:**  \n",
    "  Recall for churners is 0.917, meaning about 8.3% of actual churners slip through undetected. However, precision of 0.982 means that nearly all predicted churners truly churn, which is critical when targeting retention efforts.\n",
    "\n",
    "- **Balanced trade-off:**  \n",
    "  The F1-score of 0.948 for churners reflects a solid balance between finding churners and avoiding false positives. This balance ensures that marketing or intervention resources are used efficiently.\n",
    "\n",
    "- **Business impact:**  \n",
    "  Catching over 91% of churners with very few false positives translates into more targeted retention campaigns and reduced wasted spend. The model’s stability across splits inspires confidence for deployment.\n",
    "\n",
    "Overall, the network not only yields stellar metrics but does so in a stable, business-actionable way, particularly by reliably flagging at-risk customers while keeping false-alarm rates minimal.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Conclutions \n",
    "\n",
    "Overall, our scratch-built neural network demonstrates impressive versatility and reliability. It handles both binary classification and true multi-class problems through a softmax output, and its modular components—activations, initializations, optimizers, learning-rate schedules, and L2 regularization—offer a broad hyperparameter space for systematic tuning. Training curves show stable convergence without dramatic oscillations, and the clear, well-organized codebase in `src/` plus accompanying notebooks makes it easy to integrate enhancements like dropout for improved generalization or swap in alternative loss functions and output layers to tackle regression tasks. This lightweight yet powerful framework serves as an excellent foundation for exploring advanced ideas and scaling up to deeper architectures in future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pablo Reyes** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
